* Getting Diospyros Numbers

Run Diospyros experiments on the server. We're using =master= instead of the ASPLOS tag because we want to use the latest version of Rosette.

#+begin_src async-shell :dir (ec2/tramp "exp" "diospyros") :results none :name dios
# git checkout master
# git pull -r

make
cargo build --release --manifest-path /home/ubuntu/diospyros/src/dios-egraphs/Cargo.toml
tmux new -d -s diospyros
tmux send-keys -t diospyros "python3 evaluation/eval_benchmarks.py --timeout 180 --skiprun -o results-t180" ENTER
# python3 evaluation/eval_benchmarks.py --timeout 180 --skiprun -o results-t180
#+end_src

Copy the results back here, so that we can analyze them.

#+begin_src async-shell :dir (sgt/dir "server") :var IP=(ec2/get-ip "exp") :results none :name dios
rsync -avh ubuntu@$IP:~/diospyros/results-t1000/ completed/diospyros/2
#+end_src

#+header: :dir (ec2/tramp "exp" "custom-diospyros")
#+begin_src async-shell :results none :name dios
DIR="../comp-gen/server/completed/qr-decomp_4/3/results"
./dios -w 4 --egg --suppress-git -o $DIR/kernel.c $DIR
#+end_src

Some changes to diospyros are needed before we can run estimation. We need to go into =evaluation/shared.mk= and edit the paths so that they point to the right places.

I don't have the expert matrix kernel, so I comment out that from the =mat-mul/harness.c=

The nature files seem to be in a different location than what Dios expects. So I symlinked the =.c= files into where they are supposed to be. Here's the command (from the fusion_g3 library):

#+begin_src async-shell :name dios :dir ~/Research/xtensa/fusiong3_library
# mat-mul nature objects
ln -s matrix/matmmltf_pdx4.c matmmltf_pdx4.c

# 2d-conv nature objects
ln -s filter/2d/conv2df_pdx4.c conv2df_pdx4.c

# qr-decomp nature objects
ln -s matinv/qrf/matinvqrf_pdx4.c matinvqrf_pdx4.c
ln -s matinv/qrf/matinvqrrotf_pdx4.c matinvqrrotf_pdx4.c
ln -s matrix/transpmf_pdx4.c transpmf_pdx4.c
ln -s matrix/transpm32cache_pdx4.c transpm32cache_pdx4.c
#+end_src

Finally, the command to actually perform cycle estimates on all the benchmarks.

#+header: :dir (sgt/dir ".." "cucapra-diospyros")
#+begin_src async-shell :name dios :results none
python3 evaluation/eval_benchmarks.py \
        --skipsynth \
        -o ~/Research/comp-gen/server/completed/diospyros/2
#+end_src

** Syncing diospyros-results between machines

#+begin_src async-shell :name dios :dir (sgt/dir "server") :results none
rsync -avh samthomas@sgt.csres.utexas.edu:~/Research/comp-gen/server/diospyros-results-log/ \
      diospyros-results-log
#+end_src

* Start jobs and sync data

Create jobs.

#+begin_src async-shell :dir (sgt/dir "server/") :results none :name sync
./jobs.py
ls jobs
#+end_src

Sync jobs.

#+begin_src async-shell :dir (sgt/dir "server") :results none :name sync
./sync.py both --name isaria --dir "~"
#+end_src

Check on server log

#+begin_src async-shell :dir (ec2/tramp "isaria" "~") :results none :name sync
podman logs --tail 50 --latest
#+end_src

* Data processing
:PROPERTIES:
:header-args:async-shell: :dir (sgt/dir "server") :results none
:END:

Testing my cycle-estimation script. At the moment, this will assume a completely compile =kernel.c= file. At some point I'll want to make this work for an arbitrary egg input.

(header args for doing cycle estimation from non-thelio computers)

#+header: :dir (sgt/dir "server/")
#+begin_src async-shell :name estimation
# ./estimate.py many latest --key noeqsat --override-name noeqsat --force
# ./estimate.py many Mar29-1443 --key performance --force
./estimate.py many latest --key alpha-beta
#+end_src

#+begin_src async-shell :name sync
rsync -avh samthomas@sgt.csres.utexas.edu:~/Research/comp-gen/server/completed/ completed
# rsync -avh \
#       --exclude "*compile-log.txt" \
#       completed/ samthomas@sgt.csres.utexas.edu:~/Research/comp-gen/server/completed
#+end_src

Process all the log files and generate data csvs.

#+begin_src async-shell :name processed
./process.py all completed/
#+end_src

Run query to generate aggregated data files

#+begin_src async-shell :name query
python3.11 query.py
#+end_src

Rewriting my =query.py= script.

#+begin_src async-shell :name query
# ./query2.py update optimization
./query2.py update large --commit
# ./query2.py update alpha_beta --commit
#+end_src

* Pictures!!
:PROPERTIES:
:header-args:R: :session cycest :colnames yes
:END:

Set working directory, import the R libraries that we will use, and import plotting code.

#+begin_src R :results none :var CWD=(sgt/dir "server" "figs")
setwd(CWD)

library(tidyverse)
library(extrafont)
library(ggpattern)
library(tikzDevice)
library(xtable)
library(gtable)
library(grid)
#+end_src

** DONE Cycle count
CLOSED: [2023-03-29 Wed 10:03]
:LOGBOOK:
- State "DONE"       from "WAITING"    [2023-03-29 Wed 10:03]
:END:

#+header: :width 6.85 :height 2.85
#+begin_src R :results graphics output file :file cycles-performance.tikz
source("R/cycles.R")
cycles()
#+end_src

#+RESULTS:
[[file:cycles-performance.tikz]]

#+begin_src R :session cycest
data <- full_join(full_join(
  read_csv("data/stock_cycles.csv"),
  read_csv("data/est_cycles.csv")
  %>% filter(timeout == "180")
  %>% filter(params != "18x18_2x2")
  %>% filter(params != "18x18_3x3")
  %>% filter(params != "18x18_4x4")
  %>% filter(params != "18x18_18x18")
  %>% filter(params != "20x20_20x20")
), read_csv("data/noeqsat.csv"))

data %>% filter(kernel == "nature" | kernel == "compgen") %>%
  select(kernel, benchmark, params, cycles) %>%
  pivot_wider(
    names_from=kernel,
    values_from=cycles
  ) %>%
  mutate(
    speedup=nature / compgen 
  ) %>% summarise(mean = mean(speedup, na.rm = T), n = n())
#+end_src

#+RESULTS:
|             mean |  n |
|------------------+----|
| 3.27463214032345 | 21 |

** DONE Compilation time
CLOSED: [2023-04-16 Sun 10:04]
:LOGBOOK:
- State "DONE"       from "NEXT"       [2023-04-16 Sun 10:04]
:END:

#+header: :width 13 :height 5  :file compile-times.svg

#+header: :width 3.3 :height 2 :file compile-times.tikz
#+begin_src R :results graphics file
source("R/compilation.R")
compilation()
#+end_src

#+RESULTS:
[[file:compile-times.tikz]]

** DONE Pruning
CLOSED: [2023-04-18 Tue 12:19]
:LOGBOOK:
- State "DONE"       from "TODO"       [2023-04-18 Tue 12:19]
:END:

#+header: :width 300 :height 200

#+header: :width 3.3 :height 2 :file pruning.tikz
#+begin_src R :results graphics file
source("R/pruning.R")
pruning()
#+end_src

#+RESULTS:
[[file:pruning.tikz]]

#+begin_src R :results output file :file pruning-table.tex
data <- read_csv("data/pruning.csv", col_names=T, show_col_types=F, progress=F)
data <- data %>% select(params, pruning, cycles, compile_time, memory_used) %>%
  mutate(memory_used=as.numeric(recode(memory_used, "killed"="-1"))) %>%
  mutate_if(is.numeric, round, 2) %>%
  mutate(
    params=params %>% str_replace_all(c("_"=" ")),
    pruning=recode(as.character(pruning), "TRUE"="Yes", "FALSE"="No"),
    memory_used=recode(as.character(memory_used), "-1"="killed"),
  )

print(
  xtable(data),
  include.rownames=F,
  sanitize.colnames.function = function(x) {
    x %>% str_replace_all(c(
            "params"="\\\\textbf{2DConv}",
            "pruning"="\\\\textbf{Pruning?}",
            "cycles"="\\\\textbf{Cycles}",
            "compile_time"="\\\\textbf{Time (s)}",
            "memory_used"="\\\\textbf{RAM (gb)}"
          ))
  },
  sanitize.text.function = function(x) {
    x
    ## x %>% str_replace_all(c(
    ##         "2x2"="2$^2$",
    ##         "3x3"="3$^2$",
    ##         "4x4"="4$^2$",
    ##         "8x8"="8$^2$",
    ##         "10x10"="10$^2$",
    ##         "16x16"="16$^2$",
    ##         "18x18"="16$^2$"
    ##       ))
  },
  hline.after = rep(seq(0, by=2, len=14))
)
#+end_src

#+RESULTS:
[[file:pruning-table.tex]]

** DONE Ruleset ablation
CLOSED: [2023-04-18 Tue 14:34]
:LOGBOOK:
- State "DONE"       from              [2023-04-18 Tue 14:34]
:END:

#+header: :width 11 :height 4

#+header: :width 3.3 :height 2 :file ruleset-ablation.tikz
#+begin_src R :results graphics file
source("R/ruleset_ablation.R")
ruleset_ablation()
#+end_src

#+RESULTS:
[[file:ruleset-ablation.tikz]]

** DONE Instruction Ablation
CLOSED: [2023-04-18 Tue 14:34]
:LOGBOOK:
- State "DONE"       from              [2023-04-18 Tue 14:34]
:END:

#+header: :results output file :file instruction.tex
#+begin_src R 
data <- read_csv(
  "data/instruction.csv",
  show_col_types=F,
  progress=F,
  col_names=T
) %>%
  filter(benchmark == "qr-decomp") %>%
  mutate(
    muls=if_else(str_detect(rules, "muls"), "VecMulSub", "No VecMulSub"),
    sqrtsgn=if_else(str_detect(rules, "sqrtsgn"), "VecSqrtSgn", "No VecSqrtSgn"),
    speedup=(1198.0 / cycles) * 100,
    show=if_else(speedup >= 100,
                 str_c("+", round(speedup-100, 1), "%"),
                 str_c("-", 100-speedup, "%"))
  ) %>%
  select(muls, sqrtsgn, show) %>%
  pivot_wider(names_from=muls, values_from=show) %>%
  mutate(` `=sqrtsgn) %>%
  select(` `, `MULS`, `No MULS`)

print(xtable(
  data,
  caption=str_c(
    "Cycle estimates for QR-Decomp for all",
    " combinations of including MAC and MULS instructions."
  ),
  label="tab:instruction"
), include.rownames=FALSE)
#+end_src

#+RESULTS:
[[file:instruction.tex]]

** Misc

#+begin_src R :results graphics file :file iter_cost.svg
data <- read.csv("data/2d-conv-3x3_3x3_iter.csv")

data %>%
  group_by(pruning) %>%
  mutate(cost = cost / max(cost)) %>%
  ggplot(aes(x=index, y=cost, group=pruning, color=pruning)) +
  geom_line() + geom_point() +
  theme_minimal() +
  labs(x="Iteration", y="Cost / max(Cost)", color="Cost Function") +
  theme(
    legend.position = c(0.80, 0.90),
    legend.background = element_rect(fill = "white"),
    text = element_text(size=16, face="bold")
  )
#+end_src

#+RESULTS:
[[file:iter_cost.svg]]

*** Backoff scheduler doesn't work

#+begin_src R :results graphics file :file scheduler-backoff.svg
data <- read.csv("~/Research/comp-gen/server/completed/2d-conv_3x3_3x3/20/data.csv")

data %>%
  filter(name == "nodes" | name == "cost" & iteration != "report") %>%
  pivot_wider(
    names_from = name,
    values_from = value
  ) %>%
  mutate(
    cost = as.numeric(cost),
    nodes = as.numeric(nodes),
  ) %>%
  ggplot(aes(
    x=log10(nodes),
    y=cost/max(cost)
  )) +
  geom_path(linewidth=1.5) + geom_point(size=2) +
  ylim(0, 1) +
  theme_minimal() + theme(
    legend.position = c(0.85, 0.9),
    legend.background = element_rect(fill = "white"),
    text = element_text(size=16, face="bold")
  )
#+end_src

#+RESULTS:
[[file:scheduler-backoff.svg]]

#+begin_src R :results graphics file :file scheduler-backoff-cost.svg
data <- read.csv("data/backoff_cost.csv")

data %>%
  filter(benchmark == "2d-conv") %>%
  filter(params == "3x3_2x2") %>%
  ggplot(aes(
    x=iteration,
    y=value)) +
  geom_path() +
  theme_minimal() + theme(
    legend.position = c(0.85, 0.9),
    legend.background = element_rect(fill = "white"),
    text = element_text(size=16, face="bold")
  )
  
  ## filter(name == "nodes" | name == "cost" & iteration != "report") %>%
  ## pivot_wider(
  ##   names_from = name,
  ##   values_from = value
  ## ) %>%
  ## mutate(
  ##   cost = as.numeric(cost),
  ##   nodes = as.numeric(nodes),
  ## ) %>%
  ## ggplot(aes(
  ##   x=log10(nodes),
  ##   y=cost/max(cost)
  ## )) +
  ## geom_path(linewidth=1.5) + geom_point(size=2) +
  ## ylim(0, 1) +
#+end_src

#+RESULTS:
[[file:scheduler-backoff-cost.svg]]
*** TODO Greedy Cost Works

The data here is wrong I think. Fix the data

#+begin_src R :results graphics file :file greedy_cost.svg
data <- read.csv("data/greedy_cost_works.csv")

# fix the order of the df in place
data$params <- factor(data$params, levels=rev(unique(data$params)))

data %>%
  filter(benchmark == "2d-conv") %>%
  ggplot(aes(fill=costfn, x=params, y=egraph_cost)) +
  geom_bar(position="dodge", stat="identity", color="black") +
  ## geom_text(
  ##   aes(label=round(egraph_cost)),
  ##   color="black",
  ##   size=3.5,
  ##   position=position_dodge(0.9)) +
  labs(x="Params", y="EGraph Cost", fill="Cost Function") +
  coord_flip() + theme_minimal() +
  theme(
    legend.position = c(0.80, 0.90),
    legend.background = element_rect(fill = "white"),
    text = element_text(size=16, face="bold")
  )
  ## theme(axis.text.x = element_text(angle = 45, vjust = 0.9, hjust=1))
#+end_src

#+RESULTS:
[[file:greedy_cost.svg]]

** Rule Distribution

#+header: :width 8 :height 4

#+header: :width 3.3 :height 2
#+begin_src R :results graphics file :file rule_distribution.tikz
source("R/rule_distribution.R")
alpha_v <- 15
beta_v <- 12
rule_distribution(alpha=alpha_v, beta=beta_v)
#+end_src

#+RESULTS:
[[file:rule_distribution.tikz]]

#+header: :width 8 :height 4

#+header: :width 3.3 :height 2
#+begin_src R :results graphics file :file alpha_beta.tikz
data <- read_csv("data/alpha_beta.csv")

data %>%
  ggplot() +
  geom_tile(
    aes(x = as.factor(beta * 2), y = as.factor(alpha), fill = cycles),
    color="black"
  ) +
  geom_tile(
    aes(x = as.factor(beta_v), y = as.factor(alpha_v)),
    fill = NA,
    color="salmon", lwd=0.7
  ) +
  ## geom_text(
  ##   aes(
  ##     x = as.factor(beta_v),
  ##     y = as.factor(alpha_v),
  ##     label = (data %>% filter(alpha==alpha_v) %>% filter(beta==beta_v / 2))$exp
  ##   ),
  ##   color = "white",
  ##   size = 2
  ## ) +
  labs(
    title="Estimated Cycles for 2d-conv $16^2 \\times 4^2$",
    x="$\\beta$ (aggregate cost)",
    y="$\\alpha$ (cost differential)"
  ) +
  scale_fill_gradient(na.value = NA) +
  guides(
    fill = guide_colorbar(
      barwidth=0.3,
      barheight=8,
      ticks=F
    ),
    color = "none"
  ) +
  theme(
    axis.title.x = element_text(size=7, face="bold"),
    axis.title.y = element_text(size=7, face="bold"),
    
    axis.text.x = element_text(size=6, color="black"),
    axis.text.y = element_text(size=7, color="black"),

    legend.position = "right",
    legend.background = element_blank(),
    legend.text = element_text(size=7),
    legend.title = element_blank(),
    legend.key.size = unit(0.75, "lines"),
    legend.box.spacing = unit(0, "lines"), 
    legend.spacing.x = unit(0.2, "lines"),
    legend.margin = margin(0, 0, 5, 2),

    panel.background = element_blank(),
    panel.spacing.x = unit(0.4, "lines"),

    strip.background = element_blank(),
    ## strip.text = element_text(size=8, face="bold", margin=margin(0, 0, 4, 0)),

    plot.title = element_text(size=8, face="bold", hjust=0.5),
    plot.margin = margin(1, 0, 1, 0)
  )
#+end_src

#+RESULTS:
[[file:alpha_beta.tikz]]

#+begin_src async-shell :results none :name latex :dir (sgt/dir ".." "comp-gen-paper")
sleep 1
make single
#+end_src

* Tables
:PROPERTIES:
:header-args:R: :session cycest :colnames yes
:END:

Generate the SLoC table for the evaluation section

#+begin_src async-shell :dir (sgt/dir) :results none :ansi t
# compgen library
cd comp-gen
compgen=$(tokei src -o json | jq .Total.code)
cd ..

cd dios-lang
spec=$(tokei src -o json | \
           jq ".Rust.reports[] | select(.name == \"src/synthesis.rs\") | .stats.code")
cost=$(tokei src -o json | \
           jq ".Rust.reports[] | select(.name == \"src/cost.rs\") | .stats.code")
harness=$(tokei src -o json | jq .Total.code)

echo "\\\newcommand{\\\sloccompgen}{$compgen}"
echo "\\\newcommand{\\\slocspec}{$spec}"
echo "\\\newcommand{\\\sloccost}{$cost}"
echo "\\\newcommand{\\\slocharness}{$((harness - spec - cost))}"
echo "\\\newcommand{\\\sloctotal}{$((compgen + harness))}"
#+end_src

Compute numbers in the paper

#+begin_src R :results none
data <- full_join(
  full_join(
    read_csv("data/est_cycles.csv", col_names=T, show_col_types=F),
    read_csv("data/long.csv", col_names=T, show_col_types=F)
  ),
  read_csv("data/diospyros.csv", col_names=T, show_col_types=F)
  %>% mutate(timeout=180),
)

data %>%
  select(kernel, benchmark, params, timeout, cycles) %>%
  filter(kernel == "compgen" | kernel == "nature" | kernel == "naive.clang") %>%
  pivot_wider(names_from=c(kernel, timeout), values_from=cycles) %>%
  print(n=100) %>%
  mutate(
    nature_su_180 = nature_180 / compgen_180,
    nature_mean_180 = exp(mean(log(nature_su_180), na.rm=T)),
    nature_su_1800 = nature_180 / compgen_1800,
    nature_mean_1800 = exp(mean(log(nature_su_1800), na.rm=T)),

    naive.clang_su_180 = naive.clang_180 / compgen_180,
    naive.clang_mean_180 = exp(mean(log(naive.clang_su_180), na.rm=T)),
    naive.clang_su_1800 = naive.clang_180 / compgen_1800,
    naive.clang_mean_1800 = exp(mean(log(naive.clang_su_1800), na.rm=T)),

    self_su = compgen_180 / compgen_1800,
    self_geomean_su = exp(mean(log(self_su), na.rm=T)),
  ) %>%
  summarise(
    nature_geomean_180=max(nature_mean_180),
    nature_min_180=min(nature_su_180, na.rm=T),
    nature_median_180=median(nature_su_180, na.rm=T),
    nature_max_180=max(nature_su_180, na.rm=T),
    nature_geomean_1800=max(nature_mean_1800),
    nature_min_1800=min(nature_su_1800, na.rm=T),
    nature_max_1800=max(nature_su_1800, na.rm=T),

    clang_geomean_180=max(naive.clang_mean_180),
    clang_min_180=min(naive.clang_su_180, na.rm=T),
    clang_max_180=max(naive.clang_su_180, na.rm=T),
    clang_geomean_1800=max(naive.clang_mean_1800),
    clang_min_1800=min(naive.clang_su_1800, na.rm=T),
    clang_max_1800=max(naive.clang_su_1800, na.rm=T),

    self_su=max(self_geomean_su),
  ) %>% pivot_longer(everything())

## cycles <- data %>%
##   select(kernel, benchmark, params, cycles) %>%
##   pivot_wider(names_from=kernel, values_from=cycles) %>%
##   select(benchmark, params, compgen, nature, naive.clang) %>%
##   mutate(
##     nature_su = nature / compgen,
##     clang_su = naive.clang / compgen
##   )

## # nature
## vals <- (cycles %>% filter(!is.na(nature_su)))$nature_su
## print(vals)
## nature_su <- exp(mean(log(vals)))
## print("nature")
## print(round(nature_su, 2))

## # clang
## vals <- (cycles %>% filter(!is.na(clang_su)))$clang_su
## clang_su <- exp(mean(log(vals)))
## print("clang")
## print(round(clang_su, 2))

## # diospyros cycles
## print("cycles")
## data %>%
##   select(kernel, benchmark, params, cycles) %>%
##   pivot_wider(names_from=kernel, values_from=cycles) %>%
##   select(benchmark, params, compgen, dios) %>%
##   filter(params != "8x8_8x8") %>%
##   filter(params != "10x10_10x10") %>%
##   mutate(
##     x = dios / compgen
##   ) %>%
##   print(n=26) %>%
##   summarize(mean = round(exp(mean(log(x))), 2),
##             median = median(x))

# diospyros time
print("time")
data %>%
  filter(timeout==180) %>%
  mutate(
    time=if_else(is.na(compile_time), eqsat_time, compile_time)
  ) %>%
  select(kernel, benchmark, params, time) %>%
  pivot_wider(names_from=kernel, values_from=time) %>%
  select(benchmark, params, compgen, dios) %>%
  filter(compgen != 0) %>%
  mutate(
    x = compgen / dios
  ) %>% summarize(mean = exp(mean(log(x))), median = median(x))
#+end_src

Ruleset ablation numbers

#+begin_src R :results none
data <- read_csv("data/ruleset_ablation.csv")

data %>%
  select(benchmark, params, ruleset, cycles) %>%
  pivot_wider(names_from=ruleset, values_from=cycles) %>%
  mutate(
    speedup=`60` / `60000`
  ) %>%
  print(n=100) %>%
  summarize(
    max = max(speedup),
    mean = exp(mean(log(speedup)))
  )
#+end_src

* Overview Example

For exposition purposes, we want to explain /why/ these large ruleset blow up the graph. Ideally we want to find a particular rule that does this.

#+header: :dir (ec2/tramp "overview" "comp-gen")
#+begin_src async-shell :results none :name overview
export compgen_bin="cargo run --release --manifest-path=$(realpath dios-lang/Cargo.toml)"
export dios_bin=$(realpath ../custom-diospyros/dios)
export dios_example_bin=$(realpath ../custom-diospyros/dios-example-gen)

cd server/overview/
time ./run.sh
#+end_src

* Copy Images to paper

#+begin_src async-shell :results none
DEST=$(realpath ~/Research/comp-gen-paper/figures)

fswatch . | while read f; do
    if [ "${f#*.}" = "tikz" ]; then
        echo "Exporting $f to $DEST/$(basename $f .tikz).tex"
        cp "$f" "$DEST/$(basename $f .tikz).tex"
    fi

    if [ "${f#*.}" = "tex" ]; then
        echo "Exporting $f to $DEST/$(basename $f .tex).tex"
        cp "$f" "$DEST/$(basename $f .tex).tex"
    fi

    if [ "${f#*.}" = "png" ]; then
        echo "Exporting $f to $DEST/$(basename $f .png).png"
        cp "$f" "$DEST/../$(basename $f .png).png"
    fi
done
#+end_src

* Debugging

#+header: :dir (sgt/dir "server" "test")
#+begin_src async-shell :name test :results none
ROOT="/home/samthomas/Research/xtensa/RI-2021.8-linux/XtensaTools/bin"

$ROOT/xt-clang++ -std=c++11 -mlongcalls \
                 -O3 -LNO:simd -LNO:simd_v -fvectorize -mtext-section-literals \
                 -DXCHAL_HAVE_FUSIONG_SP_VFPU=1 \
                 kernel.c -S

$ROOT/xt-clang++ -std=c++11 -mlongcalls \
                 -O3 -LNO:simd -fvectorize -mtext-section-literals \
                 -DXCHAL_HAVE_FUSIONG_SP_VFPU=1 \
                 kernel.c harness.c -o run.o

$ROOT/xt-run --client_commands='trace --level=0 trace.out' run.o
#+end_src

#+header: :dir (sgt/dir "server")
#+begin_src async-shell :name test
EXP="diospyros-results-log/2d-conv/3x3_3x3_4r"
make -C ~/Research/diospyros dios
~/Research/diospyros/dios -w 4 --egg --suppress-git -o $EXP/kernel.c $EXP
cp harnesses/utils.h $EXP
cp harnesses/2d-conv.c $EXP/harness.c
./estimate.py single --force --results "." --name 2d-conv --params 3x3_3x3 $EXP
#+end_src

#+begin_src async-shell :name test :dir (sgt/dir "server") :results none
DIR=completed/mat-mul_8x8_8x8/20
# ~/Research/diospyros/dios -w 4 --egg --suppress-git \
#                           -o $DIR/results/kernel.c \
#                           $DIR/results
# ./estimate.py single $DIR --debug --force
./correlate.py $DIR/results/kernel.s $DIR/results/kernel.c
#+end_src

Debug a job by running it locally

#+begin_src async-shell :dir (sgt/dir "server") :results none :name debug :ansi t
export compgen_bin="cargo run --release --manifest-path=$(realpath ../dios-lang/Cargo.toml)"
export dios_bin=$(realpath ../../diospyros/dios)
export dios_example_bin=$(realpath ../../diospyros/dios-example-gen)

DIR="completed/qr-decomp_3/78"
cd $DIR
./run.sh 2>stderr.log
cd ../..

# make -C ../../diospyros dios
# ./estimate.py single $DIR --debug --force
# ./correlate.py $DIR/results/kernel.s $DIR/results/kernel.c
#+end_src

Debugging why our synthesizer doesn't generate rules like =(sqrt 1) <-> 1=

#+begin_src async-shell :dir (sgt/dir) :results none :ansi t
RUST_LOG=info,egg=info,z3=off cargo run --release --manifest-path=dios-lang/Cargo.toml -- \
      synth server/test/out.json --config server/synthesis/debug.json
#+end_src

* Potential Names

Chourmas

Equality saturation, synthesis, closure, DSP, vector

Ekastos (each, every, in greek) ἕκᾰστος
