#+title: Artifact Evaluation ASPLOS'24 AEC Spring

Website: https://sites.google.com/view/asplos24aec/home
HotCRP: https://asplos24aec-spring.hotcrp.com/

(forgive the wording for now, I'll improve later)

Here are the instructions to:
1) reproduce the figures in our paper
2) demonstrate the robustness of our artifact by showing how to extend it

Many of our experiments require large amounts of memory to complete, and access to proprietary tools to compile kernels for the Tensilica architecture and perform cycle estimation. Educational licenses are available for free [[https://www.cadence.com/en_US/home/company/cadence-academic-network/university-program.html][here]], but we also separate out the generation of the data from the making of plots. We provide all of the data that we used for the paper.

For each figure, we will split instructions into how to generate the data, and how to make the plot. We will provide the data so that you can generate the plots without waiting for all the experiments to run.

* Software Prerequisites

You will need the following software to replicate our results.

** Podman or Docker (for re-running experiments)

The experiment server is containerized, so you need a client to run the container. Podman and Docker will both work, and have the same CLI interface. Choose whatever you prefer.

OS specific instructions for installing podman can be found here: https://podman.io/get-started

OS specific Instructions for installing docker can be found here: https://www.docker.com/get-started/

** R (for making plots)

*** Mac Installation

I recommend that you use [[https://brew.sh/][brew]] to install R.

=brew install r=

If you don't want to do that for some reason. The R binaries are here: https://cran.r-project.org/bin/macosx/

*** Linux Installation

Refer to your distributions instructions on how to install R.

** AWSCLI (optional dependency)

This makes it easier to run experiments on EC2 machines. You can name machines and pass their names to various scripts instead of their IP addresses.

Installation instructions are here: https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html

Then you will have to connect the CLI to your account:  https://docs.aws.amazon.com/cli/latest/userguide/getting-started-quickstart.html

* Starting the experiment server

If you want to re-run our experiments, you will need to setup the experiment server. You can run locally on your machine, or remotely on a machine with more resources.

The server is distributed as a container, with all of it's dependencies bundled. This should hopefully make it easy to set up. All you need is a container manager. I prefer =podman=, but =docker= should work the same.

** Podman

Instructions for installing podman are here: https://podman.io/docs/installation

Then, download the Isaria image.

#+begin_src async-shell
podman pull ghcr.io/sgpthomas/isaria-aec:latest
#+end_src

You will need to make two directories on the host to hold queued jobs and completed jobs.

#+begin_src async-shell
mkdir -p completed jobs
#+end_src

If you don't have an =Xtensa= installation setup, you will not be able to run cycle estimation, but you can still run Isaria. In this case, start the server with:

#+begin_src async-shell
podman run --rm -d \
       -v ./completed:/root/comp-gen/server/completed \
       -v ./jobs:/root/comp-gen/server/jobs \
       --name isaria \
       ghcr.io/sgpthomas/isaria-aec
#+end_src

Otherwise, if you do have an =Xtensa= installation, the following command will start the server with the capability of performing cycle-estimation.

#+begin_src async-shell
podman run --rm -d \
       -v ./completed:/root/comp-gen/server/completed \
       -v ./jobs:/root/comp-gen/server/jobs \
       -v ./xtensa:/root/xtensa \
       --network slirp4netns:allow_host_loopback=true \
       --name isaria \
       ghcr.io/sgpthomas/isaria-aec
#+end_src

You will also need to start the license server on the host (not inside container). You can do that with:

#+begin_src async-shell
./x64_lsb/lmgrd -c LICENSE \
                -z # add -z if you want to start the license daemon attached to a TTY
                   # this is useful for debugging
#+end_src

** TODO Docker

*WARNING*: untested

Instructions for installing docker are here: https://www.docker.com/get-started/.

Then, download the Isaria image.

#+begin_src async-shell
docker pull ghcr.io/sgpthomas/isaria-aec:latest
#+end_src

You will need to make two directories on the host to hold queued jobs and completed jobs.

#+begin_src async-shell
mkdir -p completed jobs
#+end_src

If you don't have an =Xtensa= installation setup, you will not be able to run cycle estimation, but you can still run Isaria. Start the server with:

#+begin_src async-shell
docker run --rm -d \
       -v ./completed:/root/comp-gen/server/completed \
       -v ./jobs:/root/comp-gen/server/jobs \
       --name isaria \
       ghcr.io/sgpthomas/isaria-aec
#+end_src

Otherwise, if you do have an =Xtensa= installation, the following command will start the server with the capability of performing cycle-estimation.

#+begin_src async-shell
docker run --rm -d \
       -v ./completed:/root/comp-gen/server/completed \
       -v ./jobs:/root/comp-gen/server/jobs \
       -v ./xtensa:/root/xtensa \
       --network slirp4netns:allow_host_loopback=true \
       --name isaria \
       ghcr.io/sgpthomas/isaria-aec
#+end_src

* Reproducing paper results
:PROPERTIES:
:header-args:async-shell: :name aec :results none :dir (sgt/dir "server")
:END:

This section provides a guide on how to generate all of the data needed for the figures presented in the paper, as well as how to generate the plots themselves. For every experiment, the workflow is to
1) generate "jobs" that run the experiments
2) give jobs to the experiment server
3) gather completed jobs and generate figures

We have provided all of the data that we used in the paper, so that you can generate the figures without waiting for all the experiments to finish.

For some jobs, you will also need to run cycle estimation. This requires access to the proprietary Xtensa toolchain. They offer educational licenses for free. [[id:setup_xtensa][Here]] are instructions for setting up the tools. For the purposes of artifact evaluation, we will provide a server with the necessary tools installed.

Most of the larger kernels require large amounts of memory. To fully reproduce our results, you will need a machine with XXX ram.

** Overall performance (Figure 4 & 5)

These figures explore how well the programs that an Isaria compiler generates performs compared against Diospyros, and some other tools. We look at both the estimated cycles of compiled programs as well as how long it took to generate them.

*** Generate data

#+begin_src async-shell
# generates jobs that run Isaria on all benchmarks
./jobs.py overall_performance

# generates a job that runs cycle estimation on all benchmarks
./jobs.py "estimate:performance" --after performance

# generates a job that reproduces the original Diospyros numbers
./jobs.py diospyros
#+end_src

If the experiment server is running locally, =./jobs.py= will put jobs into the correct location be default. Otherwise, you have to copy them to the server yourself.

#+begin_src async-shell
./sync.py upload --ip <ip-of-machine> --dir "~/jobs" --clean
#+end_src

Once the experiments have finished (there are no jobs left in the jobs directory), you can copy the data locally again with:

#+begin_src async-shell
./sync.py download --ip <ip-of-machine> --dir "~/completed" --clean
#+end_src

Then, we can collate the data.

#+begin_src async-shell
./query2.py asdf
#+end_src

**** EC2 instructions

#+begin_src async-shell
./sync.py upload --name <name-of-ec2-machine> --dir "~/jobs" --clean
#+end_src

*** TODO Make Plots

** Exploration of the effect of pruning (Figure 6)

*** Generate data
*** Make Plots

** Exploration of time spent generating rules (Figure 7)

*** Generate Data
*** Make Plots

** Adding new instructions (Table 2)

*** Generate Data
*** Make Plots

** Exploring the effect of alpha and beta parameters (Figure 8 & 9)

*** Generate Data
*** Make Plots

* Generating all the data
:PROPERTIES:
:header-args:async-shell: :name jobs :results none :dir (sgt/dir "server")
:END:

** DONE Overall Performance (Figure 4)
CLOSED: [2023-09-19 Tue 10:19]
:LOGBOOK:
- State "DONE"       from "TODO"       [2023-09-19 Tue 10:19]
:END:

*** Comp-gen Numbers

First generate the jobs.

#+begin_src async-shell
./jobs.py overall_performance
#+end_src

Take a look at what is generated in =server/jobs=

Then copy them to the server. The =--clean= flag removes the local copies of the jobs once they have been uploaded to the server.

#+begin_src async-shell
./sync.py upload --name isaria --dir "~/jobs" --clean
#+end_src

*** Diospyros Numbers

#+begin_src async-shell
./jobs.py diospyros
#+end_src

#+begin_src async-shell
./sync.py upload --name isaria --dir "~/jobs" --clean
#+end_src

*** Estimation

Run the estimation job

#+begin_src async-shell
./jobs.py "estimate:performance"
./sync.py update --name isaria --dir "~/jobs" --clean
#+end_src

*** Download results

#+begin_src async-shell
./sync.py download --name isaria --dir "~/completed"
#+end_src

** DONE Compilation Time (Figure 5)
CLOSED: [2023-09-20 Wed 10:09]
:LOGBOOK:
- State "DONE"       from "TODO"       [2023-09-20 Wed 10:09]
:END:

This uses the overall performance numbers. No new experiments needed.

** DONE Pruning (Figure 6)
CLOSED: [2023-09-19 Tue 10:19]
:LOGBOOK:
- State "DONE"       from "TODO"       [2023-09-19 Tue 10:19]
:END:

This needs the pruning experiments.

#+begin_src async-shell
./jobs.py pruning
#+end_src

Upload the jobs.

#+begin_src async-shell
./sync.py upload --name isaria --dir "~/jobs" --clean
#+end_src

** TODO Ruleset Ablation (Figure 7)

We first need to synthesize rulesets.

The following command will generate the jobs needed for that.

#+begin_src async-shell
./jobs.py ruleset_synthesis
#+end_src

Then we need to compile them with Isaria.

And generate estimation for them. This requires the rulesets existing. If they don't, the job creation can't exist. I would like to be able to start these jobs with the rulesets pre-existing. I probably should put them somewhere else, and then have the person copy them to the right location and name them the right things? Or maybe I don't need them to name them the right things.

*TODO*: run this after running ruleset synthesis

#+begin_src async-shell
./jobs.py ruleset_ablation
#+end_src

#+begin_src async-shell
./jobs.py "estimate:ruleset_ablation"
#+end_src

** TODO New Instructions (Table 2)

This generates the new rulesets.

#+begin_src async-shell
./jobs.py new_instructions_ruleset
#+end_src

And this runs Isaria on them. However, this job seems wack. Because I'm adding rules?? And hardcoding the synthesis path. I should probably change it.

#+begin_src async-shell
./jobs.py test_instruction_ruleset
#+end_src

** TODO Rule Distribution (Figure 8)

This doesn't require any more experiments. We can just grab one of the rule_distribution.csv that we have generated from above. Or maybe we should just generate it from the ruleset directly. I should probably do that.

** DONE Alpha Beta Ablation (Figure 9)
CLOSED: [2023-09-19 Tue 11:29]
:LOGBOOK:
- State "DONE"       from "TODO"       [2023-09-19 Tue 11:29]
:END:

#+begin_src async-shell
./jobs.py alpha_beta_ablation
#+end_src

* Making Figures
* Making a change
* Nitty-Gritty details

This section is for the brave who want to build the experiment server container (or run the server outside of a container). 

** Building experiment server container with =buildah=
:PROPERTIES:
:header-args:async-shell: :name buildah :results none
:END:

To build, you need =buildah= and a relatively up-to-date =fedora= machine. To keep the image as small as possible, we start the image from just a base file system and use the host package manager to install packages in the image. Running the =aec/fedora-build-image.sh= inside of a =buildah unshare= session should do all the hard-work for you.

#+begin_src async-shell
buildah unshare ./aec/fedora-build-image.sh
#+end_src

If you want to build and run the server from scratch, read the =fedora-build-image= script to see what all the dependencies are.

** TODO Setting up =XtensaTools=
:PROPERTIES:
:ID: setup_xtensa
:END:


